{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first round rmse: 0.0281364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('societe_generale_training.csv',parse_dates=['time_stamp'])\n",
    "test = pd.read_csv('societe_generale_test.csv',parse_dates=['time_stamp'])\n",
    "submission = pd.read_csv('societe_generale_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_number</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>1 year</th>\n",
       "      <th>2 year</th>\n",
       "      <th>3 year</th>\n",
       "      <th>4 year</th>\n",
       "      <th>6 year</th>\n",
       "      <th>7 year</th>\n",
       "      <th>8 year</th>\n",
       "      <th>9 year</th>\n",
       "      <th>10 year</th>\n",
       "      <th>15 year</th>\n",
       "      <th>20 year</th>\n",
       "      <th>25 year</th>\n",
       "      <th>30 year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   serial_number time_stamp  1 year  2 year  3 year  4 year  6 year  7 year  \\\n",
       "0              1 2019-01-15  -0.160  -0.153  -0.154  -0.149  -0.146  -0.146   \n",
       "1              2 2019-01-11  -0.148  -0.153  -0.157  -0.155  -0.152  -0.150   \n",
       "2              3 2019-01-10  -0.147  -0.148  -0.154  -0.155  -0.146  -0.146   \n",
       "3              4 2019-01-09  -0.144  -0.147  -0.154  -0.152  -0.141  -0.136   \n",
       "4              5 2019-01-08  -0.146  -0.147  -0.158  -0.160  -0.152  -0.146   \n",
       "\n",
       "   8 year  9 year  10 year  15 year  20 year  25 year  30 year  \n",
       "0  -0.105  -0.045    0.014    0.269    0.486    0.605    0.696  \n",
       "1  -0.107  -0.046    0.014    0.269    0.488    0.605    0.696  \n",
       "2  -0.102  -0.036    0.024    0.279    0.505    0.621    0.710  \n",
       "3  -0.092  -0.033    0.029    0.286    0.519    0.631    0.720  \n",
       "4  -0.102  -0.049    0.014    0.269    0.500    0.614    0.706  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method='ffill')\n",
    "test = test.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8430, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,[2,3,4,5,7,8,9,10,11,12,13,14,15]]\n",
    "y = data.iloc[:,6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid , y_train, y_valid = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_train = lgb.Dataset(X_train,y_train)\n",
    "lgbm_valid = lgb.Dataset(X_valid,y_valid,reference=lgbm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'objective': 'regression',\n",
    "          'metric': 'rmse',\n",
    "          'bagging_freq':5,\n",
    "          'feature_fraction':0.9,\n",
    "          'max_depth':100,\n",
    "          'num_leaves':450,\n",
    "          'learning_rate':0.3\n",
    "          \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 2.0726\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's rmse: 1.45108\n",
      "[3]\tvalid_0's rmse: 1.01591\n",
      "[4]\tvalid_0's rmse: 0.711235\n",
      "[5]\tvalid_0's rmse: 0.498469\n",
      "[6]\tvalid_0's rmse: 0.349716\n",
      "[7]\tvalid_0's rmse: 0.245718\n",
      "[8]\tvalid_0's rmse: 0.173555\n",
      "[9]\tvalid_0's rmse: 0.123705\n",
      "[10]\tvalid_0's rmse: 0.089611\n",
      "[11]\tvalid_0's rmse: 0.0668045\n",
      "[12]\tvalid_0's rmse: 0.0520029\n",
      "[13]\tvalid_0's rmse: 0.0429645\n",
      "[14]\tvalid_0's rmse: 0.037635\n",
      "[15]\tvalid_0's rmse: 0.0347205\n",
      "[16]\tvalid_0's rmse: 0.033044\n",
      "[17]\tvalid_0's rmse: 0.0321422\n",
      "[18]\tvalid_0's rmse: 0.0316025\n",
      "[19]\tvalid_0's rmse: 0.0311122\n",
      "[20]\tvalid_0's rmse: 0.0307261\n",
      "[21]\tvalid_0's rmse: 0.0305544\n",
      "[22]\tvalid_0's rmse: 0.0303496\n",
      "[23]\tvalid_0's rmse: 0.0303033\n",
      "[24]\tvalid_0's rmse: 0.0300179\n",
      "[25]\tvalid_0's rmse: 0.0298104\n",
      "[26]\tvalid_0's rmse: 0.0297566\n",
      "[27]\tvalid_0's rmse: 0.0296479\n",
      "[28]\tvalid_0's rmse: 0.0294908\n",
      "[29]\tvalid_0's rmse: 0.0294155\n",
      "[30]\tvalid_0's rmse: 0.0293213\n",
      "[31]\tvalid_0's rmse: 0.029141\n",
      "[32]\tvalid_0's rmse: 0.0291352\n",
      "[33]\tvalid_0's rmse: 0.0290362\n",
      "[34]\tvalid_0's rmse: 0.0289871\n",
      "[35]\tvalid_0's rmse: 0.0289101\n",
      "[36]\tvalid_0's rmse: 0.0289158\n",
      "[37]\tvalid_0's rmse: 0.0288365\n",
      "[38]\tvalid_0's rmse: 0.0287677\n",
      "[39]\tvalid_0's rmse: 0.0286822\n",
      "[40]\tvalid_0's rmse: 0.0286338\n",
      "[41]\tvalid_0's rmse: 0.0285829\n",
      "[42]\tvalid_0's rmse: 0.0284956\n",
      "[43]\tvalid_0's rmse: 0.0284139\n",
      "[44]\tvalid_0's rmse: 0.0283708\n",
      "[45]\tvalid_0's rmse: 0.0283785\n",
      "[46]\tvalid_0's rmse: 0.0283666\n",
      "[47]\tvalid_0's rmse: 0.0282988\n",
      "[48]\tvalid_0's rmse: 0.0282626\n",
      "[49]\tvalid_0's rmse: 0.0281797\n",
      "[50]\tvalid_0's rmse: 0.0281793\n",
      "[51]\tvalid_0's rmse: 0.0281725\n",
      "[52]\tvalid_0's rmse: 0.0280726\n",
      "[53]\tvalid_0's rmse: 0.0280467\n",
      "[54]\tvalid_0's rmse: 0.0279601\n",
      "[55]\tvalid_0's rmse: 0.0279793\n",
      "[56]\tvalid_0's rmse: 0.0279092\n",
      "[57]\tvalid_0's rmse: 0.0278783\n",
      "[58]\tvalid_0's rmse: 0.0278775\n",
      "[59]\tvalid_0's rmse: 0.0278717\n",
      "[60]\tvalid_0's rmse: 0.0278387\n",
      "[61]\tvalid_0's rmse: 0.0278031\n",
      "[62]\tvalid_0's rmse: 0.0277908\n",
      "[63]\tvalid_0's rmse: 0.027764\n",
      "[64]\tvalid_0's rmse: 0.0277606\n",
      "[65]\tvalid_0's rmse: 0.0277371\n",
      "[66]\tvalid_0's rmse: 0.027699\n",
      "[67]\tvalid_0's rmse: 0.0276895\n",
      "[68]\tvalid_0's rmse: 0.0276498\n",
      "[69]\tvalid_0's rmse: 0.0276366\n",
      "[70]\tvalid_0's rmse: 0.0276029\n",
      "[71]\tvalid_0's rmse: 0.0276174\n",
      "[72]\tvalid_0's rmse: 0.0275974\n",
      "[73]\tvalid_0's rmse: 0.0276135\n",
      "[74]\tvalid_0's rmse: 0.0275318\n",
      "[75]\tvalid_0's rmse: 0.0275197\n",
      "[76]\tvalid_0's rmse: 0.0275226\n",
      "[77]\tvalid_0's rmse: 0.0275263\n",
      "[78]\tvalid_0's rmse: 0.0275114\n",
      "[79]\tvalid_0's rmse: 0.0274812\n",
      "[80]\tvalid_0's rmse: 0.0274709\n",
      "[81]\tvalid_0's rmse: 0.0274566\n",
      "[82]\tvalid_0's rmse: 0.0274249\n",
      "[83]\tvalid_0's rmse: 0.0274425\n",
      "[84]\tvalid_0's rmse: 0.0274211\n",
      "[85]\tvalid_0's rmse: 0.0274123\n",
      "[86]\tvalid_0's rmse: 0.0274173\n",
      "[87]\tvalid_0's rmse: 0.0274015\n",
      "[88]\tvalid_0's rmse: 0.0274065\n",
      "[89]\tvalid_0's rmse: 0.027402\n",
      "[90]\tvalid_0's rmse: 0.0273696\n",
      "[91]\tvalid_0's rmse: 0.0273423\n",
      "[92]\tvalid_0's rmse: 0.0273715\n",
      "[93]\tvalid_0's rmse: 0.0273456\n",
      "[94]\tvalid_0's rmse: 0.0273279\n",
      "[95]\tvalid_0's rmse: 0.0273098\n",
      "[96]\tvalid_0's rmse: 0.027335\n",
      "[97]\tvalid_0's rmse: 0.02731\n",
      "[98]\tvalid_0's rmse: 0.0273012\n",
      "[99]\tvalid_0's rmse: 0.0273264\n",
      "[100]\tvalid_0's rmse: 0.0272989\n",
      "[101]\tvalid_0's rmse: 0.0273097\n",
      "[102]\tvalid_0's rmse: 0.0273222\n",
      "[103]\tvalid_0's rmse: 0.0273109\n",
      "[104]\tvalid_0's rmse: 0.0272966\n",
      "[105]\tvalid_0's rmse: 0.0272678\n",
      "[106]\tvalid_0's rmse: 0.0272921\n",
      "[107]\tvalid_0's rmse: 0.0272931\n",
      "[108]\tvalid_0's rmse: 0.0272587\n",
      "[109]\tvalid_0's rmse: 0.0272705\n",
      "[110]\tvalid_0's rmse: 0.0272572\n",
      "[111]\tvalid_0's rmse: 0.0272613\n",
      "[112]\tvalid_0's rmse: 0.0272648\n",
      "[113]\tvalid_0's rmse: 0.0272538\n",
      "[114]\tvalid_0's rmse: 0.0272301\n",
      "[115]\tvalid_0's rmse: 0.0272225\n",
      "[116]\tvalid_0's rmse: 0.0272206\n",
      "[117]\tvalid_0's rmse: 0.0272334\n",
      "[118]\tvalid_0's rmse: 0.0272162\n",
      "[119]\tvalid_0's rmse: 0.0271955\n",
      "[120]\tvalid_0's rmse: 0.0271635\n",
      "[121]\tvalid_0's rmse: 0.0271507\n",
      "[122]\tvalid_0's rmse: 0.0271652\n",
      "[123]\tvalid_0's rmse: 0.0271317\n",
      "[124]\tvalid_0's rmse: 0.027119\n",
      "[125]\tvalid_0's rmse: 0.0271439\n",
      "[126]\tvalid_0's rmse: 0.0271372\n",
      "[127]\tvalid_0's rmse: 0.0271369\n",
      "[128]\tvalid_0's rmse: 0.0271335\n",
      "[129]\tvalid_0's rmse: 0.027155\n",
      "[130]\tvalid_0's rmse: 0.0271328\n",
      "[131]\tvalid_0's rmse: 0.0271391\n",
      "[132]\tvalid_0's rmse: 0.0271174\n",
      "[133]\tvalid_0's rmse: 0.0271021\n",
      "[134]\tvalid_0's rmse: 0.0270808\n",
      "[135]\tvalid_0's rmse: 0.0270975\n",
      "[136]\tvalid_0's rmse: 0.0270835\n",
      "[137]\tvalid_0's rmse: 0.0270975\n",
      "[138]\tvalid_0's rmse: 0.0270724\n",
      "[139]\tvalid_0's rmse: 0.02709\n",
      "[140]\tvalid_0's rmse: 0.0270761\n",
      "[141]\tvalid_0's rmse: 0.0270627\n",
      "[142]\tvalid_0's rmse: 0.0270363\n",
      "[143]\tvalid_0's rmse: 0.027052\n",
      "[144]\tvalid_0's rmse: 0.0270379\n",
      "[145]\tvalid_0's rmse: 0.0270342\n",
      "[146]\tvalid_0's rmse: 0.0270474\n",
      "[147]\tvalid_0's rmse: 0.0270391\n",
      "[148]\tvalid_0's rmse: 0.0270296\n",
      "[149]\tvalid_0's rmse: 0.0270348\n",
      "[150]\tvalid_0's rmse: 0.0270083\n",
      "[151]\tvalid_0's rmse: 0.0270114\n",
      "[152]\tvalid_0's rmse: 0.0270284\n",
      "[153]\tvalid_0's rmse: 0.0269945\n",
      "[154]\tvalid_0's rmse: 0.0269879\n",
      "[155]\tvalid_0's rmse: 0.0269744\n",
      "[156]\tvalid_0's rmse: 0.0269654\n",
      "[157]\tvalid_0's rmse: 0.0269488\n",
      "[158]\tvalid_0's rmse: 0.026972\n",
      "[159]\tvalid_0's rmse: 0.0269506\n",
      "[160]\tvalid_0's rmse: 0.0269693\n",
      "[161]\tvalid_0's rmse: 0.0269482\n",
      "[162]\tvalid_0's rmse: 0.0269376\n",
      "[163]\tvalid_0's rmse: 0.0269335\n",
      "[164]\tvalid_0's rmse: 0.0269596\n",
      "[165]\tvalid_0's rmse: 0.0269457\n",
      "[166]\tvalid_0's rmse: 0.0269345\n",
      "[167]\tvalid_0's rmse: 0.0269451\n",
      "[168]\tvalid_0's rmse: 0.0269322\n",
      "[169]\tvalid_0's rmse: 0.0269204\n",
      "[170]\tvalid_0's rmse: 0.0269355\n",
      "[171]\tvalid_0's rmse: 0.0269272\n",
      "[172]\tvalid_0's rmse: 0.0269188\n",
      "[173]\tvalid_0's rmse: 0.0269058\n",
      "[174]\tvalid_0's rmse: 0.0268907\n",
      "[175]\tvalid_0's rmse: 0.0269006\n",
      "[176]\tvalid_0's rmse: 0.026891\n",
      "[177]\tvalid_0's rmse: 0.0268856\n",
      "[178]\tvalid_0's rmse: 0.0268717\n",
      "[179]\tvalid_0's rmse: 0.0268905\n",
      "[180]\tvalid_0's rmse: 0.0268708\n",
      "[181]\tvalid_0's rmse: 0.0268813\n",
      "[182]\tvalid_0's rmse: 0.0268799\n",
      "[183]\tvalid_0's rmse: 0.0268634\n",
      "[184]\tvalid_0's rmse: 0.0268471\n",
      "[185]\tvalid_0's rmse: 0.0268415\n",
      "[186]\tvalid_0's rmse: 0.0268493\n",
      "[187]\tvalid_0's rmse: 0.0268321\n",
      "[188]\tvalid_0's rmse: 0.0268423\n",
      "[189]\tvalid_0's rmse: 0.0268346\n",
      "[190]\tvalid_0's rmse: 0.0268215\n",
      "[191]\tvalid_0's rmse: 0.0268217\n",
      "[192]\tvalid_0's rmse: 0.0268379\n",
      "[193]\tvalid_0's rmse: 0.0268335\n",
      "[194]\tvalid_0's rmse: 0.0268302\n",
      "[195]\tvalid_0's rmse: 0.0268424\n",
      "[196]\tvalid_0's rmse: 0.0268223\n",
      "[197]\tvalid_0's rmse: 0.0268416\n",
      "[198]\tvalid_0's rmse: 0.0268173\n",
      "[199]\tvalid_0's rmse: 0.0268198\n",
      "[200]\tvalid_0's rmse: 0.0268305\n",
      "[201]\tvalid_0's rmse: 0.0268252\n",
      "[202]\tvalid_0's rmse: 0.0268226\n",
      "[203]\tvalid_0's rmse: 0.0268067\n",
      "[204]\tvalid_0's rmse: 0.0268069\n",
      "[205]\tvalid_0's rmse: 0.0268247\n",
      "[206]\tvalid_0's rmse: 0.026809\n",
      "[207]\tvalid_0's rmse: 0.0268186\n",
      "[208]\tvalid_0's rmse: 0.0268147\n",
      "[209]\tvalid_0's rmse: 0.0267977\n",
      "[210]\tvalid_0's rmse: 0.0267932\n",
      "[211]\tvalid_0's rmse: 0.0267756\n",
      "[212]\tvalid_0's rmse: 0.0267601\n",
      "[213]\tvalid_0's rmse: 0.0267749\n",
      "[214]\tvalid_0's rmse: 0.0267589\n",
      "[215]\tvalid_0's rmse: 0.0267453\n",
      "[216]\tvalid_0's rmse: 0.0267558\n",
      "[217]\tvalid_0's rmse: 0.02674\n",
      "[218]\tvalid_0's rmse: 0.0267568\n",
      "[219]\tvalid_0's rmse: 0.0267472\n",
      "[220]\tvalid_0's rmse: 0.0267503\n",
      "[221]\tvalid_0's rmse: 0.0267632\n",
      "[222]\tvalid_0's rmse: 0.0267509\n",
      "[223]\tvalid_0's rmse: 0.0267492\n",
      "[224]\tvalid_0's rmse: 0.026765\n",
      "[225]\tvalid_0's rmse: 0.0267571\n",
      "[226]\tvalid_0's rmse: 0.0267572\n",
      "[227]\tvalid_0's rmse: 0.026743\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's rmse: 0.02674\n"
     ]
    }
   ],
   "source": [
    "gbm = lgb.train(\n",
    "                params,\n",
    "               lgbm_train,\n",
    "               valid_sets=lgbm_valid,\n",
    "                num_boost_round=2000,\n",
    "                early_stopping_rounds=10\n",
    "                #verbose_eval=False # verbose = 0\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GS:\n",
    "    grid_params = {#'max_depth' : [100,200],\n",
    "                   #'num_leaves' : [450,460,470],\n",
    "                    #'learning_rate': [0.3,0.31,0.25]\n",
    "                    #'feature_fraction': [0.9,1],\n",
    "                    #'bagging_fraction': [1],\n",
    "                    #'bagging_freq' : [5,6]\n",
    "    }\n",
    "    mdl = lgb.LGBMRegressor(boosting_type= params['boosting_type'], # these will be commented when the parameter is in grid_params, uncomment when you get the best results.\n",
    "                           objective = params['objective'],\n",
    "                            metric = params['metric'],\n",
    "                            #num_leaves = params['num_leaves'], \n",
    "                            #learning_rate = params['learning_rate'],\n",
    "                            #feature_fraction = params['feature_fraction'],\n",
    "                            #bagging_fraction = params['bagging_fraction'],\n",
    "                            #bagging_freq = params['bagging_freq']\n",
    "                           )\n",
    "    grid = GridSearchCV(mdl,\n",
    "                       grid_params,\n",
    "                        cv = 5,\n",
    "                        scoring = 'neg_mean_squared_error'\n",
    "                       )\n",
    "    grid.fit(X_train,y_train)\n",
    "    print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_buff = []\n",
    "n_itr = 5\n",
    "for i in range(n_itr):\n",
    "    X_train, X_valid , y_train, y_valid = train_test_split(X,y,test_size=0.2,random_state=i) # random state is the number in the iteration\n",
    "    lgbm_train = lgb.Dataset(X_train,y_train) # Preparing data for lgb\n",
    "    lgbm_valid = lgb.Dataset(X_valid,y_valid,reference=lgbm_train) # Preparing data for lgb\n",
    "    \n",
    "    gbm_itr = lgb.train(\n",
    "                params,\n",
    "               lgbm_train,\n",
    "               valid_sets=lgbm_valid,\n",
    "                num_boost_round=2000,\n",
    "                early_stopping_rounds=50, # stop if the results do not improve in 5 rounds\n",
    "                verbose_eval=False # verbose = 0\n",
    "               )\n",
    "    \n",
    "    y_pred = gbm.predict(X_test,\n",
    "                     num_iteration=gbm.best_iteration) # run the number of iterations for the best number\n",
    "    pred_buff.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if submit:\n",
    "    submission['5 year'] = y_pred\n",
    "    submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
